{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.layers import MaxPooling2D, Input, Concatenate, Dense, Dropout, Activation, Flatten, Conv2D, Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D, BatchNormalization, Flatten, GRU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compte rendu de classification\n",
    "def cpt_mal_classes(y_test_func, result_func):\n",
    "    nb_func = 0\n",
    "    for i in range(len(y_test_func)):\n",
    "        if y_test_func[i] != result_func[i]:\n",
    "            nb_func += 1\n",
    "    print (f'Taille des données {len(y_test_func)} mal classés {nb_func}\\n')\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "# Display image in actual size\n",
    "def display_image_in_actual_size(im_path):\n",
    "\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "    height, width, depth = im_data.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Output').mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recharger les données d'entraînement, de validation et test en fichier numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recharger les données après avoir vidé la mémoire\n",
    "train_X = np.load('Data/train_valid_test/train_X.npy')\n",
    "train_y = np.load('Data/train_valid_test/train_y.npy')\n",
    "\n",
    "valid_X = np.load('Data/train_valid_test/valid_X.npy')\n",
    "valid_y = np.load('Data/train_valid_test/valid_y.npy')\n",
    "valid_id = np.load('Data/train_valid_test/valid_id.npy')\n",
    "\n",
    "test_X = np.load('Data/train_valid_test/test_X.npy')\n",
    "test_id = np.load('Data/train_valid_test/test_id.npy')\n",
    "\n",
    "train_X1 = train_X[:,2,2,:,:]\n",
    "valid_X1 = valid_X[:,2,2,:,:]\n",
    "test_X1 = test_X[:,2,2,:,:]\n",
    "\n",
    "train_X2 = train_X[:,:,:,:].reshape(train_X.shape[0],20,20,-1)\n",
    "valid_X2 = valid_X[:,:,:,:].reshape(valid_X.shape[0],20,20,-1)\n",
    "test_X2 = test_X[:,:,:,:].reshape(test_X.shape[0],20,20,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder les labels entre 0 et 4 de sorte à matcher les prédictions des réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(train_y)\n",
    "train_y_enc = encoder.transform(train_y)\n",
    "valid_y_enc = encoder.transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inputs \n",
    "cnn1d_input = Input(shape=(8, 4),name='cnn1d_input')\n",
    "cnn2d_input = Input(shape=(20, 20, 2),name='cnn2d_input')\n",
    "\n",
    "# CNN1D branch\n",
    "cnn1d_layer1 = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn1d_input)\n",
    "cnn1d_layer1 = BatchNormalization()(cnn1d_layer1)\n",
    "\n",
    "cnn1d_layer2 = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn1d_layer1)\n",
    "cnn1d_layer2 = BatchNormalization()(cnn1d_layer2)\n",
    "cnn1d_layer2 = Dropout(0.5)(cnn1d_layer2)\n",
    "\n",
    "cnn1d_layer3 = GlobalAveragePooling1D()(cnn1d_layer2)\n",
    "\n",
    "cnn1d_out = Dense(5, activation='softmax', name='cnn1d')(cnn1d_layer3)\n",
    "\n",
    "cnn1d_branch = Model(inputs=cnn1d_input, outputs=[cnn1d_layer3, cnn1d_out], name=\"cnn1d\")\n",
    "\n",
    "# CNN2D branch\n",
    "cnn2d_layer1 = Conv2D(filters=32,kernel_size=(5,5),activation='relu')(cnn2d_input)\n",
    "cnn2d_layer1 = MaxPooling2D(pool_size=(2, 2))(cnn2d_layer1)\n",
    "\n",
    "cnn2d_layer2 = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(cnn2d_layer1)\n",
    "\n",
    "cnn2d_layer3 = Flatten()(cnn2d_layer2)\n",
    "\n",
    "cnn2d_out = Dense(5,activation='softmax',name='cnn2d')(cnn2d_layer3)\n",
    "\n",
    "cnn2d_branch = Model(inputs=cnn2d_input,outputs=[cnn2d_layer3,cnn2d_out],name=\"cnn2d\")\n",
    "\n",
    "# Concaténation des sorties des branches\n",
    "concat = Concatenate()([cnn1d_branch.output[0],cnn2d_branch.output[0]])\n",
    "\n",
    "# Un niveau Dense pour la classification\n",
    "# fc = Dense (128,activation='relu')(concat)\n",
    "# fc = Dropout (0.5)(fc)\n",
    "out_layer = Dense(5,activation='softmax',name='main')(concat)\n",
    "\n",
    "model = Model(inputs=[cnn1d_branch.input, cnn2d_branch.input], outputs=[out_layer, cnn1d_branch.output[1], cnn2d_branch.output[1]], name=\"cnn1d_cnn2d\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, 'Output/cnn1d_cnn2d.png', show_shapes=True)\n",
    "\n",
    "display_image_in_actual_size('Output/cnn1d_cnn2d.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = tf.keras.optimizers.Adam(0.0001)\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 25\n",
    "CALLBACKS = [tf.keras.callbacks.ModelCheckpoint(\n",
    "              'Model/model',\n",
    "              verbose=1, # niveau de log\n",
    "              monitor='val_main_acc', # nom de la métrique à surveiller\n",
    "              save_best_only=True, # sauver uniquement le meilleur modèle\n",
    "              save_weights_only=True)] # sauver uniquement les poids\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=tf.keras.losses.SparseCategoricalCrossentropy(), loss_weights=[1, .5, .5], metrics=tf.keras.metrics.SparseCategoricalAccuracy(name='acc'))\n",
    "\n",
    "history = model.fit([train_X1, train_X2], train_y_enc, validation_data=([valid_X1, valid_X2], valid_y_enc), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model/Best_CNN1D_CNN2D')\n",
    "\n",
    "model_loaded1 = model.load_weights('Model/model')\n",
    "model_loaded2 = keras.models.load_model('Model/Best_CNN1D_CNN2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['main_acc'])\n",
    "plt.plot(history.history['val_main_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([valid_X1, valid_X2], valid_y_enc, batch_size=256)\n",
    "\n",
    "print(f'Loss : {score[1]:.2f}')\n",
    "print(f'Accuracy : {score[4]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prédiction des classes sur le jeu de validation et évaluation en aggrégeant au niveau objet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les probabilités prédites sur le jeu de validation\n",
    "valid_prob, _, _ = model.predict([valid_X1, valid_X2], batch_size=256)\n",
    "\n",
    "# Retourner la classe correspondant à la probabilité la plus haute\n",
    "valid_pred = np.argmax(valid_prob, axis=1) # axe 1 car ceci concerne chaque ligne\n",
    "\n",
    "# Je réencode les prédictions entre 1 et 5\n",
    "valid_pred_enc = encoder.inverse_transform(valid_pred)\n",
    "\n",
    "# Aggrégation au niveau objet\n",
    "out_pred = []\n",
    "unique_id = np.unique(valid_id)\n",
    "for ID in unique_id :\n",
    "    # Récupérer les prédictions des pixels appartenant au même objet\n",
    "    pred = valid_pred_enc[np.where(valid_id==ID)]\n",
    "    y_true = valid_y[np.where(valid_id==ID)]\n",
    "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
    "    out_pred.append([ np.bincount(y_true).argmax(), np.bincount(pred).argmax()]) #(Vérité terrain,Prédiction majoritaire)\n",
    "out_pred = np.vstack(out_pred)\n",
    "y_true = out_pred[:,0]\n",
    "y_pred = out_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_mal_classes(y_true, y_pred)\n",
    "print(f'F1 score : {f1_score(y_true,y_pred,average=\"weighted\"):.2f}\\n')\n",
    "print(f'Accuracy : {accuracy_score(y_pred, y_true):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(y_true, y_pred)}\\n')\n",
    "print(f'Classification report :\\n{classification_report(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prédire sur le jeu test et Préparer une soumission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les probabilités prédites sur le jeu test\n",
    "test_prob, _, _ = model.predict([test_X1, test_X2], batch_size=256)\n",
    "\n",
    "# Retourner la classe correspondant à la probabilité la plus haute\n",
    "test_pred = np.argmax(test_prob, axis=1) # axe 1 car ceci concerne chaque ligne\n",
    "\n",
    "# Je réencode les prédictions entre 1 et 5\n",
    "test_pred_enc = encoder.inverse_transform(test_pred)\n",
    "\n",
    "# Aggrégation au niveau objet\n",
    "agg_pred = []\n",
    "unique_id = np.unique(test_id)\n",
    "for ID in unique_id :\n",
    "    # Récupérer les prédictions des pixels appartenant au même objet\n",
    "    pred = test_pred_enc[np.where(test_id==ID)]\n",
    "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
    "    agg_pred.append([ ID, np.bincount(pred).argmax()]) #(ID,Prédiction majoritaire)\n",
    "agg_pred = np.vstack(agg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID':agg_pred[:, 0], 'Class':agg_pred[:, 1]})\n",
    "df_test = pd.read_csv('Data/Test_id_Label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_mal_classes(df_test.Class, df.Class)\n",
    "print(f'F1 score : {f1_score(df_test.Class,df.Class,average=\"weighted\"):.2f}\\n')\n",
    "print(f'Accuracy : {accuracy_score(df.Class, df_test.Class):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(df_test.Class, df.Class)}\\n')\n",
    "print(f'Classification report :\\n{classification_report(df_test.Class, df.Class)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(df_test.Class, df.Class), None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
