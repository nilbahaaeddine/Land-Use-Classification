{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compte rendu de classification\n",
    "def cpt_mal_classes(y_test_func, result_func):\n",
    "    nb_func = 0\n",
    "    for i in range(len(y_test_func)):\n",
    "        if y_test_func[i] != result_func[i]:\n",
    "            nb_func += 1\n",
    "    print (f'Taille des données {len(y_test_func)} mal classés {nb_func}\\n')\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path('Output').mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Recharger les données d'entraînement, de validation et test en fichier numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recharger les données après avoir vidé la mémoire\n",
    "train_X = np.load('Data/train_valid_test/train_X.npy')\n",
    "train_y = np.load('Data/train_valid_test/train_y.npy')\n",
    "\n",
    "valid_X = np.load('Data/train_valid_test/valid_X.npy')\n",
    "valid_y = np.load('Data/train_valid_test/valid_y.npy')\n",
    "valid_id = np.load('Data/train_valid_test/valid_id.npy')\n",
    "\n",
    "test_X = np.load('Data/train_valid_test/test_X.npy')\n",
    "test_id = np.load('Data/train_valid_test/test_id.npy')\n",
    "\n",
    "train_X = train_X[:,:,:,:].reshape(train_X.shape[0],20,20,-1)\n",
    "valid_X = valid_X[:,:,:,:].reshape(valid_X.shape[0],20,20,-1)\n",
    "test_X = test_X[:,:,:,:].reshape(test_X.shape[0],20,20,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encoder les labels entre 0 et 4 de sorte à matcher les prédictions des réseaux de neurones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "train_y_enc = encoder.transform(train_y)\n",
    "valid_y_enc = encoder.transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(20, 20, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(5, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = tf.keras.optimizers.Adam(0.001)\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 2\n",
    "CALLBACKS = [tf.keras.callbacks.ModelCheckpoint(\n",
    "              'Model/model',\n",
    "              verbose=1, # niveau de log\n",
    "              monitor='val_accuracy', # nom de la métrique à surveiller\n",
    "              save_best_only=True, # sauver uniquement le meilleur modèle\n",
    "              save_weights_only=True)] # sauver uniquement les poids\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_X, train_y_enc, validation_data=(valid_X,valid_y_enc), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model/Best_CNN2D')\n",
    "\n",
    "model_loaded1 = model.load_weights('Model/model')\n",
    "model_loaded2 = keras.models.load_model('Model/Best_CNN2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(valid_X, valid_y_enc, verbose = 1)\n",
    "\n",
    "print(f'Loss : {score[0]:.2f}')\n",
    "print(f'Accuracy : {score[1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prédiction des classes sur le jeu de validation et évaluation en aggrégeant au niveau objet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les probabilités prédites sur le jeu de validation\n",
    "valid_prob = model.predict(valid_X,batch_size=256)\n",
    "\n",
    "# Retourner la classe correspondant à la probabilité la plus haute\n",
    "valid_pred = np.argmax(valid_prob,axis=1) # axe 1 car ceci concerne chaque ligne\n",
    "\n",
    "# Je réencode les prédictions entre 1 et 5\n",
    "valid_pred_enc = encoder.inverse_transform(valid_pred)\n",
    "\n",
    "# Aggrégation au niveau objet\n",
    "out_pred = []\n",
    "unique_id = np.unique(valid_id)\n",
    "for ID in unique_id :\n",
    "    # Récupérer les prédictions des pixels appartenant au même objet\n",
    "    pred = valid_pred_enc[np.where(valid_id==ID)]\n",
    "    y_true = valid_y[np.where(valid_id==ID)]\n",
    "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
    "    out_pred.append([ np.bincount(y_true).argmax(), np.bincount(pred).argmax()]) #(Vérité terrain,Prédiction majoritaire)\n",
    "out_pred = np.vstack(out_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_mal_classes(out_pred[:,0], out_pred[:,1])\n",
    "print(f'F1 score : {f1_score(out_pred[:,0],out_pred[:,1],average=\"weighted\"):.2f}\\n')\n",
    "print(f'Accuracy : {accuracy_score(out_pred[:,1], out_pred[:,0]):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(out_pred[:,0], out_pred[:,1])}\\n')\n",
    "print(f'Classification report :\\n{classification_report(out_pred[:,0], out_pred[:,1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(out_pred[:,0], out_pred[:,1])\n",
    "plot_confusion_matrix(cm, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prédire sur le jeu test et Préparer une soumission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les probabilités prédites sur le jeu test\n",
    "test_prob = model.predict(test_X,batch_size=256)\n",
    "\n",
    "# Retourner la classe correspondant à la probabilité la plus haute\n",
    "test_pred = np.argmax(test_prob,axis=1) # axe 1 car ceci concerne chaque ligne\n",
    "\n",
    "# Je réencode les prédictions entre 1 et 5\n",
    "test_pred_enc = encoder.inverse_transform(test_pred)\n",
    "\n",
    "# Aggrégation au niveau objet\n",
    "agg_pred = []\n",
    "unique_id = np.unique(test_id)\n",
    "for ID in unique_id :\n",
    "    # Récupérer les prédictions des pixels appartenant au même objet\n",
    "    pred = test_pred_enc[np.where(test_id==ID)]\n",
    "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
    "    agg_pred.append([ ID, np.bincount(pred).argmax()]) #(ID,Prédiction majoritaire)\n",
    "agg_pred = np.vstack(agg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID':agg_pred[:,0],'Class':agg_pred[:,1]})\n",
    "df_test = pd.read_csv('Data/Test_id_Label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_mal_classes(df_test.Class, df.Class)\n",
    "print(f'F1 score : {f1_score(df_test.Class,df.Class,average=\"weighted\"):.2f}\\n')\n",
    "print(f'Accuracy : {accuracy_score(df.Class, df_test.Class):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(df_test.Class, df.Class)}\\n')\n",
    "print(f'Classification report :\\n{classification_report(df_test.Class, df.Class)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_test.Class, df.Class)\n",
    "plot_confusion_matrix(cm, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEFORE\n",
    "## 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.1 -> 0.8697286817613364\n",
    "# lr = 0.001 -> 0.8997192836881034\n",
    "# lr = 0.0001 -> 0.8487040808178663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Conv2D(128, kernel_size=(2, 2), input_shape=(5, 5, 32))) -> 0.8400641022343117\n",
    "# model.add(Conv2D(128, kernel_size=(3, 3), input_shape=(5, 5, 32))) -> 0.8761390096224383\n",
    "# model.add(Conv2D(128, kernel_size=(4, 4), input_shape=(5, 5, 32))) -> 0.8850564403212298\n",
    "# model.add(Conv2D(128, kernel_size=(5, 5), input_shape=(5, 5, 32))) -> 0.9043562858958935\n",
    "# model.add(Conv2D(64, kernel_size=(5, 5), input_shape=(5, 5, 32))) -> 0.8623933830390569\n",
    "# model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(5, 5, 32))) -> 0.8997192836881034\n",
    "# model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(5, 5, 32))) -> 0.861725146557579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8990454616150305 model.add(Conv2D(128, kernel_size=(5, 5), input_shape=(5, 5, 32)))\n",
    "# 0.859862467858344 model.add(Conv2D(64, kernel_size=(5, 5), input_shape=(5, 5, 32)))\n",
    "# 0.8415452782627942 model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(5, 5, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFTER\n",
    "## 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8403963187685989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8581149859321545\n",
    "# 0.833743064091453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW ONE\n",
    "## model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(20, 20, 2)),\n",
    "#         layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(5, activation=\"softmax\")\n",
    "#     ]\n",
    "# )\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(0.001)\n",
    "# EPOCHS = 25\n",
    "# # Taille des données 800 mal classés 117\n",
    "# # F1 score : 0.86\n",
    "# # Accuracy : 0.85\n",
    "\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(20, 20, 2)),\n",
    "#         layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Flatten(),\n",
    "       \n",
    "#         layers.Dense(5, activation=\"softmax\")\n",
    "#     ]\n",
    "# )\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(0.01)\n",
    "# EPOCHS = 25\n",
    "# # Taille des données 800 mal classés 120\n",
    "# # F1 score : 0.85\n",
    "# # Accuracy : 0.85\n",
    "\n",
    "# # WE NEED TO TRY THIS ONE WITH DROPOUT !!!\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(20, 20, 2)),\n",
    "#         layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(128, kernel_size=(1, 1), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(5, activation=\"softmax\")\n",
    "#     ]\n",
    "# )\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(0.001)\n",
    "# EPOCHS = 25\n",
    "# # Taille des données 800 mal classés 134\n",
    "# # F1 score : 0.83\n",
    "# # Accuracy : 0.83\n",
    "\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(20, 20, 2)),\n",
    "#         layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(5, activation=\"softmax\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(0.001)\n",
    "# EPOCHS = 25\n",
    "# # Taille des données 800 mal classés 96\n",
    "# # F1 score : 0.89\n",
    "# # Accuracy : 0.88\n",
    "\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(20, 20, 2)),\n",
    "#         layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(5, activation=\"softmax\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(0.01)\n",
    "# EPOCHS = 25\n",
    "# # Taille des données 800 mal classés 128\n",
    "# # F1 score : 0.84\n",
    "# # Accuracy : 0.84"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
